{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KNiYojZPVOjc"
      },
      "id": "KNiYojZPVOjc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download & extract PACS dataset (optional)"
      ],
      "metadata": {
        "id": "Z0D3PagO-Nvw"
      },
      "id": "Z0D3PagO-Nvw"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "361abd07",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "361abd07",
        "outputId": "218ff1f3-2f64-4186-faf8-bec8544b9b9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9991/9991 [00:15<00:00, 634.21it/s]\n"
          ]
        }
      ],
      "source": [
        "# Install deps (safe to re-run)\n",
        "!pip -q install datasets pillow tqdm\n",
        "\n",
        "import os, io\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from datasets import load_dataset\n",
        "\n",
        "root = \"/content/data/PACS\"\n",
        "os.makedirs(root, exist_ok=True)\n",
        "\n",
        "ds = load_dataset(\"flwrlabs/pacs\", split=\"train\")\n",
        "\n",
        "if \"category\" in ds.features:\n",
        "    label_field = \"category\"\n",
        "elif \"class\" in ds.features:\n",
        "    label_field = \"class\"\n",
        "elif \"label\" in ds.features:\n",
        "    label_field = \"label\"\n",
        "else:\n",
        "    raise RuntimeError(f\"Unexpected schema: {ds.features}\")\n",
        "\n",
        "def class_name(row):\n",
        "    v = row[label_field]\n",
        "    if isinstance(v, int):\n",
        "        return ds.features[label_field].names[v]\n",
        "    return str(v)\n",
        "\n",
        "# Normalize domains → art_painting/cartoon/photo/sketch\n",
        "def norm_domain(v: str):\n",
        "    s = str(v).strip().lower().replace(\" \", \"_\").replace(\"-\", \"_\")\n",
        "    if s in {\"art_painting\", \"cartoon\", \"photo\", \"sketch\"}:\n",
        "        return s\n",
        "    # map common variants just in case\n",
        "    if s in {\"artpainting\", \"art_paintings\"}:\n",
        "        return \"art_painting\"\n",
        "    return s  # fallback (we'll skip unknowns below)\n",
        "\n",
        "# Write images to /content/data/PACS/<domain>/<class>/<i>.jpg\n",
        "for i, row in tqdm(enumerate(ds), total=len(ds)):\n",
        "    dom = norm_domain(row[\"domain\"])\n",
        "    if dom not in {\"art_painting\", \"cartoon\", \"photo\", \"sketch\"}:\n",
        "        continue  # skip anything weird\n",
        "    cls = class_name(row)\n",
        "    out_dir = os.path.join(root, dom, cls)\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    img = row[\"image\"]\n",
        "    if not isinstance(img, Image.Image):\n",
        "        # Some datasets provide bytes; convert to PIL.Image\n",
        "        img = Image.open(io.BytesIO(img[\"bytes\"])).convert(\"RGB\")\n",
        "    img.save(os.path.join(out_dir, f\"{i}.jpg\"), quality=95)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports, constants, and seed"
      ],
      "metadata": {
        "id": "lspNuJ34ZpQs"
      },
      "id": "lspNuJ34ZpQs"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, random, os, numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "DATA_ROOT = \"/content/data/PACS\"\n",
        "SOURCES   = [\"art_painting\", \"cartoon\", \"photo\"]\n",
        "TARGET    = \"sketch\"\n",
        "IMG_SIZE  = 224\n",
        "BATCH_SIZE = 64\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "# seed set for reproducibility\n",
        "def set_seed(seed=1337):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(1337)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVNSHBsLZoxJ",
        "outputId": "5a2df2c3-d8b0-4b9c-bf2f-f38825077c63"
      },
      "id": "cVNSHBsLZoxJ",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "I7XLJ9EHN8Ll"
      },
      "id": "I7XLJ9EHN8Ll"
    },
    {
      "cell_type": "code",
      "source": [
        "_to_rgb = transforms.Lambda(lambda im: im.convert(\"RGB\"))\n",
        "\n",
        "def make_loaders(data_root, img_size=224, batch_size=64, num_workers=2, sources=None, target=None):\n",
        "    tfm_train = transforms.Compose([\n",
        "        _to_rgb,\n",
        "        transforms.RandomResizedCrop(img_size, scale=(0.7, 1.0)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(0.1, 0.1, 0.1, 0.05),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "    ])\n",
        "    tfm_eval = transforms.Compose([\n",
        "        _to_rgb,\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(img_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "    ])\n",
        "\n",
        "    def load_domain(name, tfm):\n",
        "        p = Path(data_root)/name\n",
        "        assert p.exists(), f\"Missing domain folder: {p}\"\n",
        "        return datasets.ImageFolder(str(p), transform=tfm)\n",
        "\n",
        "    # Build datasets\n",
        "    src_train, per_domain_eval = [], {}\n",
        "    class_to_idx = None\n",
        "\n",
        "    for d in sources:\n",
        "        ds_tr = load_domain(d, tfm_train)\n",
        "        ds_ev = load_domain(d, tfm_eval)\n",
        "        if class_to_idx is None:\n",
        "            class_to_idx = ds_tr.class_to_idx\n",
        "        else:\n",
        "            assert ds_tr.class_to_idx == class_to_idx, \"Class mapping differs across domains.\"\n",
        "        assert ds_ev.class_to_idx == class_to_idx\n",
        "        src_train.append(ds_tr)\n",
        "        per_domain_eval[d] = ds_ev\n",
        "\n",
        "    target_eval = load_domain(target, tfm_eval)\n",
        "    assert target_eval.class_to_idx == class_to_idx\n",
        "    per_domain_eval[target] = target_eval\n",
        "\n",
        "    # Loaders\n",
        "    train_ds = ConcatDataset(src_train)\n",
        "    train_loader = DataLoader(\n",
        "        train_ds, batch_size=batch_size, shuffle=True,\n",
        "        num_workers=num_workers, pin_memory=True,\n",
        "        persistent_workers=(num_workers > 0), drop_last=True\n",
        "    )\n",
        "    eval_loaders = {\n",
        "        d: DataLoader(ds, batch_size=batch_size, shuffle=False,\n",
        "                      num_workers=num_workers, pin_memory=True,\n",
        "                      persistent_workers=(num_workers > 0))\n",
        "        for d, ds in per_domain_eval.items()\n",
        "    }\n",
        "\n",
        "    num_classes = len(target_eval.classes)\n",
        "    return train_loader, eval_loaders, num_classes, target_eval.classes\n",
        "\n",
        "train_loader, eval_loaders, num_classes, classes = make_loaders(\n",
        "    DATA_ROOT, IMG_SIZE, BATCH_SIZE, NUM_WORKERS, SOURCES, TARGET\n",
        ")\n",
        "print(f\"Train size: {len(train_loader.dataset)} | Num classes: {num_classes}\")\n",
        "print(\"Domains loaded:\", list(eval_loaders.keys()))\n",
        "print(\"Classes:\", classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01Z-gRAtZ8oT",
        "outputId": "51e539d0-8dc2-4d50-d61e-6560d541ba1d"
      },
      "id": "01Z-gRAtZ8oT",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 6062 | Num classes: 7\n",
            "Domains loaded: ['art_painting', 'cartoon', 'photo', 'sketch']\n",
            "Classes: ['dog', 'elephant', 'giraffe', 'guitar', 'horse', 'house', 'person']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_resnet50(num_classes: int):\n",
        "    # pretrained ResNet-50, replace final layer\n",
        "    m = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
        "    m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
        "    return m\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loaders, device):\n",
        "    model.eval()\n",
        "    acc = {}\n",
        "    for dname, loader in loaders.items():\n",
        "        correct, total = 0, 0\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "            pred = logits.argmax(1)\n",
        "            correct += (pred == y).sum().item()\n",
        "            total   += y.numel()\n",
        "        acc[dname] = correct / max(total, 1)\n",
        "    return acc\n",
        "\n",
        "\n",
        "def train_erm(\n",
        "    sources,\n",
        "    target,\n",
        "    train_loader,\n",
        "    eval_loaders,\n",
        "    num_classes,\n",
        "    epochs=20,\n",
        "    lr=3e-4,\n",
        "    wd=0.05,\n",
        "    out_dir=\"outputs_erm\",\n",
        "    seed=1337,\n",
        "    use_amp=True,\n",
        "):\n",
        "    np.random.seed(seed); torch.manual_seed(seed)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = build_resnet50(num_classes).to(device)\n",
        "\n",
        "    opt   = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    sched = optim.lr_scheduler.CosineAnnealingLR(opt, T_max=epochs)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=(use_amp and device.type==\"cuda\"))\n",
        "\n",
        "    best_target = 0.0\n",
        "    logs = []\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        seen = 0\n",
        "\n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {ep}/{epochs}\", leave=False)\n",
        "        for x, y in pbar:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "\n",
        "            with torch.cuda.amp.autocast(enabled=(use_amp and device.type==\"cuda\")):\n",
        "                logits = model(x)\n",
        "                loss = loss_fn(logits, y)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(opt)\n",
        "            scaler.update()\n",
        "\n",
        "            running_loss += loss.item() * y.size(0)\n",
        "            seen += y.size(0)\n",
        "\n",
        "        sched.step()\n",
        "\n",
        "        acc = evaluate(model, eval_loaders, device)\n",
        "        src_accs = [acc[d] for d in sources]\n",
        "        avg_src = float(np.mean(src_accs))\n",
        "        worst_src = float(min(src_accs))\n",
        "\n",
        "        # Log\n",
        "        row = {\n",
        "            \"epoch\": ep,\n",
        "            \"train_loss\": running_loss / max(seen, 1),\n",
        "            \"target_acc\": acc[target],\n",
        "            \"avg_source_acc\": avg_src,\n",
        "            \"worst_source_acc\": worst_src,\n",
        "        }\n",
        "        for d in sources + [target]:\n",
        "            row[f\"acc_{d}\"] = acc[d]\n",
        "        logs.append(row)\n",
        "\n",
        "        print(f\"[Ep {ep:02d}] loss={row['train_loss']:.4f} | \"\n",
        "              f\"tgt({target})={acc[target]:.3f} | src_avg={avg_src:.3f} | worst_src={worst_src:.3f}\")\n",
        "\n",
        "        # Save best-by-target\n",
        "        if acc[target] > best_target:\n",
        "            best_target = acc[target]\n",
        "            torch.save(model.state_dict(), os.path.join(out_dir, \"best_model.pt\"))\n",
        "\n",
        "    df = pd.DataFrame(logs)\n",
        "    df.to_csv(os.path.join(out_dir, \"training_log.csv\"), index=False)\n",
        "    print(f\"\\nBest target ({target}) accuracy: {best_target:.3f}\")\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "0SiUxPTkaLYA"
      },
      "id": "0SiUxPTkaLYA",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Uses the loaders you already created:\n",
        "# train_loader, eval_loaders, num_classes, classes = make_loaders(...)\n",
        "\n",
        "df_logs = train_erm(\n",
        "    sources=SOURCES,\n",
        "    target=TARGET,\n",
        "    train_loader=train_loader,\n",
        "    eval_loaders=eval_loaders,\n",
        "    num_classes=num_classes,\n",
        "    epochs=20,\n",
        "    lr=3e-4,\n",
        "    wd=0.05,\n",
        "    out_dir=\"outputs_erm\",\n",
        "    seed=1337,\n",
        "    use_amp=True,   # set False if you hit AMP issues\n",
        ")\n",
        "\n",
        "# Peek last few rows\n",
        "df_logs.tail()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "id": "ymgHvjtlab8c",
        "outputId": "71975003-3f10-4596-f5c6-4c3be5bf7055"
      },
      "id": "ymgHvjtlab8c",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 156MB/s]\n",
            "/tmp/ipython-input-2102803089.py:44: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(use_amp and device.type==\"cuda\"))\n",
            "Epoch 1/20:   0%|          | 0/94 [00:00<?, ?it/s]/tmp/ipython-input-2102803089.py:60: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(use_amp and device.type==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 01] loss=0.4052 | tgt(sketch)=0.711 | src_avg=0.967 | worst_src=0.958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 02] loss=0.1278 | tgt(sketch)=0.582 | src_avg=0.976 | worst_src=0.965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 03] loss=0.0820 | tgt(sketch)=0.663 | src_avg=0.985 | worst_src=0.980\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 04] loss=0.0750 | tgt(sketch)=0.601 | src_avg=0.990 | worst_src=0.985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 05] loss=0.0539 | tgt(sketch)=0.549 | src_avg=0.984 | worst_src=0.967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 06] loss=0.0448 | tgt(sketch)=0.701 | src_avg=0.996 | worst_src=0.992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 07] loss=0.0387 | tgt(sketch)=0.734 | src_avg=0.995 | worst_src=0.987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 08] loss=0.0231 | tgt(sketch)=0.644 | src_avg=0.994 | worst_src=0.991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 09] loss=0.0165 | tgt(sketch)=0.697 | src_avg=0.998 | worst_src=0.998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 10] loss=0.0224 | tgt(sketch)=0.694 | src_avg=0.997 | worst_src=0.996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 11] loss=0.0146 | tgt(sketch)=0.724 | src_avg=1.000 | worst_src=0.999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 12] loss=0.0089 | tgt(sketch)=0.707 | src_avg=0.999 | worst_src=0.998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 13] loss=0.0076 | tgt(sketch)=0.729 | src_avg=1.000 | worst_src=1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 14] loss=0.0064 | tgt(sketch)=0.700 | src_avg=1.000 | worst_src=1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 15] loss=0.0026 | tgt(sketch)=0.689 | src_avg=1.000 | worst_src=1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 16] loss=0.0032 | tgt(sketch)=0.729 | src_avg=1.000 | worst_src=1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 17] loss=0.0044 | tgt(sketch)=0.728 | src_avg=1.000 | worst_src=1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 18] loss=0.0039 | tgt(sketch)=0.736 | src_avg=1.000 | worst_src=1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 19] loss=0.0029 | tgt(sketch)=0.728 | src_avg=1.000 | worst_src=1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 20] loss=0.0041 | tgt(sketch)=0.729 | src_avg=1.000 | worst_src=1.000\n",
            "\n",
            "Best target (sketch) accuracy: 0.736\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    epoch  train_loss  target_acc  avg_source_acc  worst_source_acc  \\\n",
              "15     16    0.003183    0.729448             1.0               1.0   \n",
              "16     17    0.004430    0.728430             1.0               1.0   \n",
              "17     18    0.003913    0.735811             1.0               1.0   \n",
              "18     19    0.002883    0.728175             1.0               1.0   \n",
              "19     20    0.004060    0.729193             1.0               1.0   \n",
              "\n",
              "    acc_art_painting  acc_cartoon  acc_photo  acc_sketch  \n",
              "15               1.0          1.0        1.0    0.729448  \n",
              "16               1.0          1.0        1.0    0.728430  \n",
              "17               1.0          1.0        1.0    0.735811  \n",
              "18               1.0          1.0        1.0    0.728175  \n",
              "19               1.0          1.0        1.0    0.729193  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1c5cfb8a-099d-4329-b407-92f37737baef\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>target_acc</th>\n",
              "      <th>avg_source_acc</th>\n",
              "      <th>worst_source_acc</th>\n",
              "      <th>acc_art_painting</th>\n",
              "      <th>acc_cartoon</th>\n",
              "      <th>acc_photo</th>\n",
              "      <th>acc_sketch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.729448</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.729448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17</td>\n",
              "      <td>0.004430</td>\n",
              "      <td>0.728430</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.728430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>0.003913</td>\n",
              "      <td>0.735811</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.735811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>19</td>\n",
              "      <td>0.002883</td>\n",
              "      <td>0.728175</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.728175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>0.004060</td>\n",
              "      <td>0.729193</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.729193</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c5cfb8a-099d-4329-b407-92f37737baef')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1c5cfb8a-099d-4329-b407-92f37737baef button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1c5cfb8a-099d-4329-b407-92f37737baef');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2cfa7964-a46e-4c48-95a8-e13a94d9821d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2cfa7964-a46e-4c48-95a8-e13a94d9821d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2cfa7964-a46e-4c48-95a8-e13a94d9821d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_logs\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 16,\n        \"max\": 20,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          17,\n          20,\n          18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0006406335672700327,\n        \"min\": 0.0028833934759840054,\n        \"max\": 0.00442992101245104,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.00442992101245104,\n          0.0040600376124394705,\n          0.00391272633792238\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0031738263968795945,\n        \"min\": 0.7281751081700178,\n        \"max\": 0.7358106388393993,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.7284296258589972,\n          0.7291931789259354,\n          0.7358106388393993\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_source_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"worst_source_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acc_art_painting\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acc_cartoon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acc_photo\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acc_sketch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0031738263968795945,\n        \"min\": 0.7281751081700178,\n        \"max\": 0.7358106388393993,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.7284296258589972\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "log_path = \"outputs_erm/training_log.csv\"\n",
        "df = pd.read_csv(log_path)\n",
        "\n",
        "best_idx = df[\"target_acc\"].idxmax()\n",
        "best = df.iloc[best_idx]\n",
        "\n",
        "summary = {\n",
        "    \"best_epoch\": int(best[\"epoch\"]),\n",
        "    \"target_sketch_acc\": round(float(best[\"target_acc\"]), 4),\n",
        "    \"avg_source_acc\": round(float(best[\"avg_source_acc\"]), 4),\n",
        "    \"worst_source_acc\": round(float(best[\"worst_source_acc\"]), 4),\n",
        "}\n",
        "for d in SOURCES + [TARGET]:\n",
        "    summary[f\"{d}_acc\"] = round(float(best[f\"acc_{d}\"]), 4)\n",
        "\n",
        "summary\n"
      ],
      "metadata": {
        "id": "nehpNYYiaixX",
        "outputId": "713e5f8d-590b-4263-8e58-2b2ccbf93123",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "nehpNYYiaixX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'best_epoch': 18,\n",
              " 'target_sketch_acc': 0.7358,\n",
              " 'avg_source_acc': 1.0,\n",
              " 'worst_source_acc': 1.0,\n",
              " 'art_painting_acc': 1.0,\n",
              " 'cartoon_acc': 1.0,\n",
              " 'photo_acc': 1.0,\n",
              " 'sketch_acc': 0.7358}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IRMv1"
      ],
      "metadata": {
        "id": "VAg0y8H5yAOQ"
      },
      "id": "VAg0y8H5yAOQ"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "_to_rgb = transforms.Lambda(lambda im: im.convert(\"RGB\"))\n",
        "\n",
        "def make_per_domain_train_loaders(data_root, img_size=224, batch_size=12, num_workers=2, sources=None):\n",
        "    # same train transform as before\n",
        "    tfm_train = transforms.Compose([\n",
        "        _to_rgb,\n",
        "        transforms.RandomResizedCrop(img_size, scale=(0.7, 1.0)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(0.1,0.1,0.1,0.05),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "    ])\n",
        "    loaders = {}\n",
        "    class_to_idx = None\n",
        "    for d in sources:\n",
        "        ds = datasets.ImageFolder(str(Path(data_root)/d), transform=tfm_train)\n",
        "        if class_to_idx is None:\n",
        "          class_to_idx = ds.class_to_idx\n",
        "        else:\n",
        "          assert ds.class_to_idx == class_to_idx\n",
        "        loaders[d] = DataLoader(ds, batch_size=batch_size, shuffle=True,\n",
        "                                num_workers=num_workers, pin_memory=True,\n",
        "                                persistent_workers=(num_workers>0), drop_last=True)\n",
        "    return loaders\n"
      ],
      "metadata": {
        "id": "MX3pbWSax_k3"
      },
      "id": "MX3pbWSax_k3",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from pathlib import Path\n",
        "\n",
        "IMG_SIZE_IRM = 224       # <= reduce from 224\n",
        "BATCH_IRM    = 12        # <= try 8 if still OOM\n",
        "NUM_WORKERS  = 0         # <= safer in Colab\n",
        "_to_rgb = transforms.Lambda(lambda im: im.convert(\"RGB\"))\n",
        "\n",
        "def make_per_domain_train_loaders(data_root, sources):\n",
        "    tfm_train = transforms.Compose([\n",
        "        _to_rgb,\n",
        "        transforms.RandomResizedCrop(IMG_SIZE_IRM, scale=(0.7, 1.0)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(0.1,0.1,0.1,0.05),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "    ])\n",
        "    loaders = {}\n",
        "    class_to_idx = None\n",
        "    for d in sources:\n",
        "        ds = datasets.ImageFolder(str(Path(data_root)/d), transform=tfm_train)\n",
        "        if class_to_idx is None: class_to_idx = ds.class_to_idx\n",
        "        else: assert ds.class_to_idx == class_to_idx\n",
        "        loaders[d] = DataLoader(\n",
        "            ds, batch_size=BATCH_IRM, shuffle=True,\n",
        "            num_workers=NUM_WORKERS, pin_memory=True,\n",
        "            persistent_workers=False, drop_last=True\n",
        "        )\n",
        "    return loaders\n"
      ],
      "metadata": {
        "id": "EHF7nMV8oNrE"
      },
      "id": "EHF7nMV8oNrE",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, numpy as np, os, random, itertools\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from torch.optim.swa_utils import AveragedModel, SWALR\n",
        "\n",
        "def build_resnet50(num_classes: int):\n",
        "    m = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
        "    # freeze all, then unfreeze layer4+layer3 first; we’ll unfreeze layer2 later\n",
        "    for p in m.parameters(): p.requires_grad = False\n",
        "    for p in m.layer4.parameters(): p.requires_grad = True\n",
        "    for p in m.layer3.parameters(): p.requires_grad = True\n",
        "    m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
        "    return m\n",
        "\n",
        "def set_bn_eval(m):\n",
        "    if isinstance(m, torch.nn.modules.batchnorm._BatchNorm):\n",
        "        m.eval()\n",
        "\n",
        "def irm_penalty(loss, dummy_w):\n",
        "    g = torch.autograd.grad(loss, [dummy_w], create_graph=True)[0]\n",
        "    return torch.sum(g**2)\n",
        "\n",
        "def train_irm(\n",
        "    sources, target, per_domain_train_loaders, eval_loaders, num_classes,\n",
        "    epochs=25, lr=3e-4, wd=0.0, out_dir=\"outputs_irm\",\n",
        "    seed=1337, use_amp=True,\n",
        "    lambda_warmup_epochs=8,    # long warmup\n",
        "    lambda_after=2.0,          # stay small & steady\n",
        "    grad_accum_steps=2,\n",
        "    domains_per_step=2,        # 2 domains per step for stable penalty\n",
        "    unfreeze_layer2_at=10,     # give more capacity mid-training\n",
        "    use_swa=True, swa_start=20 # SWA last few epochs\n",
        "):\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = build_resnet50(num_classes).to(device)\n",
        "    model = model.to(memory_format=torch.channels_last)\n",
        "    model.apply(set_bn_eval)  # freeze BN stats\n",
        "\n",
        "    opt   = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, weight_decay=wd)\n",
        "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=epochs, eta_min=1e-6)\n",
        "    ce    = nn.CrossEntropyLoss()\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=(use_amp and device.type=='cuda'))\n",
        "    torch.set_float32_matmul_precision('medium')\n",
        "\n",
        "    # SWA wrapper (activates after swa_start)\n",
        "    swa_model = AveragedModel(model) if use_swa else None\n",
        "    swa_sched = SWALR(opt, swa_lr=lr*0.5) if use_swa else None  # lr will be overridden after swa_start\n",
        "\n",
        "    # Iterators\n",
        "    domain_iters = {d: iter(per_domain_train_loaders[d]) for d in sources}\n",
        "    domains = list(sources)\n",
        "\n",
        "    best_target = 0.0\n",
        "    logs = []\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    for ep in range(1, epochs+1):\n",
        "        # λ schedule\n",
        "        lam = 0.0 if ep <= lambda_warmup_epochs else lambda_after\n",
        "\n",
        "        # unfreeze layer2 later for extra capacity\n",
        "        if ep == unfreeze_layer2_at:\n",
        "            for p in model.layer2.parameters(): p.requires_grad = True\n",
        "\n",
        "        model.train()\n",
        "        steps = min(len(ld) for ld in per_domain_train_loaders.values())\n",
        "        running_loss = 0.0\n",
        "        running_pen  = 0.0\n",
        "        seen = 0\n",
        "\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        for step in tqdm(range(steps), desc=f\"[IRM+] Epoch {ep}/{epochs}\", leave=False):\n",
        "            # pick K distinct domains this step\n",
        "            chosen = [domains[(step + k) % len(domains)] for k in range(domains_per_step)]\n",
        "            losses, penalties, batch_sizes = [], [], []\n",
        "\n",
        "            for d in chosen:\n",
        "                try:\n",
        "                    x, y = next(domain_iters[d])\n",
        "                except StopIteration:\n",
        "                    domain_iters[d] = iter(per_domain_train_loaders[d])\n",
        "                    x, y = next(domain_iters[d])\n",
        "\n",
        "                x = x.to(device, memory_format=torch.channels_last, non_blocking=True)\n",
        "                y = y.to(device, non_blocking=True)\n",
        "                w = torch.tensor(1.0, requires_grad=True, device=device)\n",
        "\n",
        "                with torch.amp.autocast('cuda', enabled=(use_amp and device.type==\"cuda\")):\n",
        "                    logits = model(x) * w\n",
        "                    loss_d = ce(logits, y)\n",
        "                pen_d = irm_penalty(loss_d, w)\n",
        "\n",
        "                losses.append(loss_d)\n",
        "                penalties.append(pen_d)\n",
        "                batch_sizes.append(y.size(0))\n",
        "\n",
        "            loss = torch.stack(losses).mean()\n",
        "            penalty = torch.stack(penalties).mean()\n",
        "            total = loss + lam * penalty\n",
        "\n",
        "            scaler.scale(total / grad_accum_steps).backward()\n",
        "            running_loss += total.item() * sum(batch_sizes)\n",
        "            running_pen  += penalty.item() * sum(batch_sizes)\n",
        "            seen += sum(batch_sizes)\n",
        "\n",
        "            if (step + 1) % grad_accum_steps == 0:\n",
        "                torch.nn.utils.clip_grad_norm_(filter(lambda p: p.requires_grad, model.parameters()), 1.0)\n",
        "                scaler.step(opt)\n",
        "                scaler.update()\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "\n",
        "        # LR schedule or SWA phase\n",
        "        if use_swa and ep >= swa_start:\n",
        "            swa_model.update_parameters(model)\n",
        "            swa_sched.step()\n",
        "        else:\n",
        "            sched.step()\n",
        "\n",
        "        # eval helper\n",
        "        @torch.no_grad()\n",
        "        def evaluate(m, loaders):\n",
        "            m.eval(); out={}\n",
        "            for name, ld in loaders.items():\n",
        "                c=t=0\n",
        "                for xb,yb in ld:\n",
        "                    xb = xb.to(device, memory_format=torch.channels_last)\n",
        "                    yb = yb.to(device)\n",
        "                    p = m(xb).argmax(1)\n",
        "                    c += (p==yb).sum().item(); t += yb.numel()\n",
        "                out[name]=c/max(t,1)\n",
        "            return out\n",
        "\n",
        "        # If SWA just started or at the end, update BN for SWA model (needs BN stats)\n",
        "        if use_swa and ep == epochs:\n",
        "            # temporarily un-freeze BN for update_bn\n",
        "            def set_bn_train(m):\n",
        "                if isinstance(m, torch.nn.modules.batchnorm._BatchNorm): m.train()\n",
        "            swa_model.apply(set_bn_train)\n",
        "            torch.optim.swa_utils.update_bn(next(iter(eval_loaders.values())), swa_model, device=device)\n",
        "            acc = evaluate(swa_model, eval_loaders)\n",
        "        else:\n",
        "            acc = evaluate(model, eval_loaders)\n",
        "\n",
        "        src_accs = [acc[d] for d in sources]\n",
        "        avg_src, worst_src = float(np.mean(src_accs)), float(min(src_accs))\n",
        "        row = {\n",
        "            \"epoch\": ep,\n",
        "            \"lambda\": lam,\n",
        "            \"train_loss\": running_loss / max(seen,1),\n",
        "            \"irm_penalty\": running_pen / max(seen,1),   # <-- report this\n",
        "            \"target_acc\": acc[target],\n",
        "            \"avg_source_acc\": avg_src,\n",
        "            \"worst_source_acc\": worst_src,\n",
        "        }\n",
        "        for d in sources+[target]:\n",
        "            row[f\"acc_{d}\"] = acc[d]\n",
        "        logs.append(row)\n",
        "\n",
        "        print(f\"[IRM+ Ep {ep:02d}] tgt={acc[target]:.3f} | src_avg={avg_src:.3f} | worst_src={worst_src:.3f} | \"\n",
        "              f\"λ={lam:.2f} | pen={row['irm_penalty']:.4f}\")\n",
        "\n",
        "        if acc[target] > best_target:\n",
        "            best_target = acc[target]\n",
        "            torch.save((swa_model if (use_swa and ep>=swa_start) else model).state_dict(),\n",
        "                       os.path.join(out_dir, \"best_model.pt\"))\n",
        "\n",
        "    df = pd.DataFrame(logs)\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    df.to_csv(os.path.join(out_dir, \"training_log.csv\"), index=False)\n",
        "    print(f\"\\n✅ IRM+ best target ({target}) acc: {best_target:.3f}\")\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "vKeTqAZGoRGE"
      },
      "id": "vKeTqAZGoRGE",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_irm = train_irm(\n",
        "    sources=SOURCES,\n",
        "    target=TARGET,\n",
        "    per_domain_train_loaders=per_domain_train,\n",
        "    eval_loaders=eval_loaders,\n",
        "    num_classes=num_classes,\n",
        "    epochs=20,\n",
        "    lr=3e-4,\n",
        "    wd=0.0,\n",
        "    out_dir=\"outputs_irm\",\n",
        "    lambda_warmup_epochs=5,\n",
        "    lambda_after=2.0,\n",
        "    grad_accum_steps=2,\n",
        "    domains_per_step=2,\n",
        "    unfreeze_layer2_at=10,\n",
        "    use_swa=True, swa_start=20,\n",
        ")\n",
        "best_idx = df_irm[\"target_acc\"].idxmax()\n",
        "best = df_irm.iloc[best_idx]\n",
        "{\n",
        "    \"best_epoch\": int(best[\"epoch\"]),\n",
        "    \"target_sketch_acc\": round(float(best[\"target_acc\"]), 4),\n",
        "    \"avg_source_acc\": round(float(best[\"avg_source_acc\"]), 4),\n",
        "    \"worst_source_acc\": round(float(best[\"worst_source_acc\"]), 4),\n",
        "    \"lambda_used\": float(best[\"lambda\"]),\n",
        "    \"irm_penalty_at_best\": round(float(best[\"irm_penalty\"]), 6),\n",
        "    **{f\"{d}_acc\": round(float(best[f\"acc_{d}\"]), 4) for d in SOURCES+[TARGET]}\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_A23XzQcoW1y",
        "outputId": "66c1f1ac-7fb4-4729-f120-fec233473c44"
      },
      "id": "_A23XzQcoW1y",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 01] tgt=0.596 | src_avg=0.892 | worst_src=0.799 | λ=0.00 | pen=0.1277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 02] tgt=0.724 | src_avg=0.942 | worst_src=0.897 | λ=0.00 | pen=0.0370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 03] tgt=0.715 | src_avg=0.946 | worst_src=0.896 | λ=0.00 | pen=0.0266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 04] tgt=0.729 | src_avg=0.969 | worst_src=0.942 | λ=0.00 | pen=0.0222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 05] tgt=0.745 | src_avg=0.984 | worst_src=0.971 | λ=0.00 | pen=0.0144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 06] tgt=0.741 | src_avg=0.983 | worst_src=0.968 | λ=0.00 | pen=0.0127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 07] tgt=0.788 | src_avg=0.986 | worst_src=0.973 | λ=0.00 | pen=0.0082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 08] tgt=0.721 | src_avg=0.976 | worst_src=0.959 | λ=0.00 | pen=0.0119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 09] tgt=0.678 | src_avg=0.966 | worst_src=0.949 | λ=2.00 | pen=0.0176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 10] tgt=0.681 | src_avg=0.964 | worst_src=0.936 | λ=2.00 | pen=0.0200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 11] tgt=0.665 | src_avg=0.979 | worst_src=0.963 | λ=2.00 | pen=0.0121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 12] tgt=0.743 | src_avg=0.974 | worst_src=0.962 | λ=2.00 | pen=0.0112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 13] tgt=0.749 | src_avg=0.975 | worst_src=0.967 | λ=2.00 | pen=0.0187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 14] tgt=0.758 | src_avg=0.978 | worst_src=0.969 | λ=2.00 | pen=0.0112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 15] tgt=0.747 | src_avg=0.969 | worst_src=0.956 | λ=2.00 | pen=0.0140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 16] tgt=0.748 | src_avg=0.980 | worst_src=0.971 | λ=2.00 | pen=0.0127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 17] tgt=0.752 | src_avg=0.979 | worst_src=0.969 | λ=2.00 | pen=0.0109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 18] tgt=0.754 | src_avg=0.976 | worst_src=0.965 | λ=2.00 | pen=0.0127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 19] tgt=0.734 | src_avg=0.980 | worst_src=0.971 | λ=2.00 | pen=0.0119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 20] tgt=0.624 | src_avg=0.973 | worst_src=0.939 | λ=2.00 | pen=0.0113\n",
            "\n",
            "✅ IRM+ best target (sketch) acc: 0.788\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'best_epoch': 7,\n",
              " 'target_sketch_acc': 0.7877,\n",
              " 'avg_source_acc': 0.9859,\n",
              " 'worst_source_acc': 0.9731,\n",
              " 'lambda_used': 0.0,\n",
              " 'irm_penalty_at_best': 0.008235,\n",
              " 'art_painting_acc': 0.9883,\n",
              " 'cartoon_acc': 0.9731,\n",
              " 'photo_acc': 0.9964,\n",
              " 'sketch_acc': 0.7877}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}