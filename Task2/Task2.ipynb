{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KNiYojZPVOjc"
      },
      "id": "KNiYojZPVOjc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download & extract PACS dataset (optional)"
      ],
      "metadata": {
        "id": "Z0D3PagO-Nvw"
      },
      "id": "Z0D3PagO-Nvw"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "361abd07",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258,
          "referenced_widgets": [
            "f0df87b7809748ecbead61c4150fb53e",
            "289c23d0a38049bd9d64ffda5a321d1a",
            "b62af46eb8a44dd29409ae640adcf324",
            "34ff2f4f644647f19cebd935ebb52638",
            "a1334ab8f77540aea2bbc476eeeb579b",
            "93f5005bb41243be9db1c4f1ea66f3ae",
            "a0e359e2805143bfae96797663a2e28e",
            "aa40f0e52cae4c72a911077760240453",
            "21f19324ab394f5c897ab262d2bb67a9",
            "c1e83dc07d3d459f92fb6e1a6e7cce96",
            "c62e2574e5f14e11b35c6c1972f3fd85",
            "497b98d3961746b8963992a55d113daf",
            "10177b20de8244d884b705385c089709",
            "a60b70d19b274b879f7bb8d14d4c8e19",
            "2ce3e5874f5e483389138402545b11e8",
            "3456c8b92bb14cf3baccf7e111251e54",
            "109cc73be387421da114780c6d9f3eb1",
            "8744ac9d325941d3b2475e9c0625f7f3",
            "3937f11ad36d444b8e55509df2fe9123",
            "b1417139cfda45aa8366c2856cfe517b",
            "372b69046a0d4d2793b20554cf01a6c8",
            "d05e42264e024c25b17e247767b7b10c",
            "324fc7031c304b27b709fa816dfde805",
            "87d781312aee4220b270ceee1b6e3c8d",
            "668c8ac529bb4f64ae76b93eedce374a",
            "4fcc9641a563401f9fcd1b36967f5eba",
            "81595689dab3475186f2ce1f86e1988e",
            "35d2b0ff19c5462983116731fb328551",
            "a74b05c612624bfaa2e0ad17bc11b6cc",
            "f68577c2276c4028b721fcd3a0332111",
            "abc903af9ea04abab6f5bdac0024f80f",
            "87ade3989ab94f6eab370eeb1ce60a11",
            "2b645addcfba47bca4e5f50a05c3d9b3"
          ]
        },
        "id": "361abd07",
        "outputId": "935144bb-ce2d-4ded-f357-f9fa0c9bb746"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f0df87b7809748ecbead61c4150fb53e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00000-of-00001.parquet:   0%|          | 0.00/191M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "497b98d3961746b8963992a55d113daf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/9991 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "324fc7031c304b27b709fa816dfde805"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9991/9991 [00:16<00:00, 600.48it/s]\n"
          ]
        }
      ],
      "source": [
        "# Install deps (safe to re-run)\n",
        "!pip -q install datasets pillow tqdm\n",
        "\n",
        "import os, io\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from datasets import load_dataset\n",
        "\n",
        "root = \"/content/data/PACS\"\n",
        "os.makedirs(root, exist_ok=True)\n",
        "\n",
        "ds = load_dataset(\"flwrlabs/pacs\", split=\"train\")\n",
        "\n",
        "if \"category\" in ds.features:\n",
        "    label_field = \"category\"\n",
        "elif \"class\" in ds.features:\n",
        "    label_field = \"class\"\n",
        "elif \"label\" in ds.features:\n",
        "    label_field = \"label\"\n",
        "else:\n",
        "    raise RuntimeError(f\"Unexpected schema: {ds.features}\")\n",
        "\n",
        "def class_name(row):\n",
        "    v = row[label_field]\n",
        "    if isinstance(v, int):\n",
        "        return ds.features[label_field].names[v]\n",
        "    return str(v)\n",
        "\n",
        "# Normalize domains → art_painting/cartoon/photo/sketch\n",
        "def norm_domain(v: str):\n",
        "    s = str(v).strip().lower().replace(\" \", \"_\").replace(\"-\", \"_\")\n",
        "    if s in {\"art_painting\", \"cartoon\", \"photo\", \"sketch\"}:\n",
        "        return s\n",
        "    # map common variants just in case\n",
        "    if s in {\"artpainting\", \"art_paintings\"}:\n",
        "        return \"art_painting\"\n",
        "    return s  # fallback (we'll skip unknowns below)\n",
        "\n",
        "# Write images to /content/data/PACS/<domain>/<class>/<i>.jpg\n",
        "for i, row in tqdm(enumerate(ds), total=len(ds)):\n",
        "    dom = norm_domain(row[\"domain\"])\n",
        "    if dom not in {\"art_painting\", \"cartoon\", \"photo\", \"sketch\"}:\n",
        "        continue  # skip anything weird\n",
        "    cls = class_name(row)\n",
        "    out_dir = os.path.join(root, dom, cls)\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    img = row[\"image\"]\n",
        "    if not isinstance(img, Image.Image):\n",
        "        # Some datasets provide bytes; convert to PIL.Image\n",
        "        img = Image.open(io.BytesIO(img[\"bytes\"])).convert(\"RGB\")\n",
        "    img.save(os.path.join(out_dir, f\"{i}.jpg\"), quality=95)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports, constants, and seed"
      ],
      "metadata": {
        "id": "lspNuJ34ZpQs"
      },
      "id": "lspNuJ34ZpQs"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, random, os, numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "DATA_ROOT = \"/content/data/PACS\"\n",
        "SOURCES   = [\"art_painting\", \"cartoon\", \"photo\"]\n",
        "TARGET    = \"sketch\"\n",
        "IMG_SIZE  = 224\n",
        "BATCH_SIZE = 64\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "# seed set for reproducibility\n",
        "def set_seed(seed=1337):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(1337)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVNSHBsLZoxJ",
        "outputId": "54ba99ff-43cd-487a-e522-f5530121cecb"
      },
      "id": "cVNSHBsLZoxJ",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "I7XLJ9EHN8Ll"
      },
      "id": "I7XLJ9EHN8Ll"
    },
    {
      "cell_type": "code",
      "source": [
        "_to_rgb = transforms.Lambda(lambda im: im.convert(\"RGB\"))\n",
        "\n",
        "def make_loaders(data_root, img_size=224, batch_size=64, num_workers=2, sources=None, target=None):\n",
        "    tfm_train = transforms.Compose([\n",
        "        _to_rgb,\n",
        "        transforms.RandomResizedCrop(img_size, scale=(0.7, 1.0)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(0.1, 0.1, 0.1, 0.05),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "    ])\n",
        "    tfm_eval = transforms.Compose([\n",
        "        _to_rgb,\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(img_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "    ])\n",
        "\n",
        "    def load_domain(name, tfm):\n",
        "        p = Path(data_root)/name\n",
        "        assert p.exists(), f\"Missing domain folder: {p}\"\n",
        "        return datasets.ImageFolder(str(p), transform=tfm)\n",
        "\n",
        "    # Build datasets\n",
        "    src_train, per_domain_eval = [], {}\n",
        "    class_to_idx = None\n",
        "\n",
        "    for d in sources:\n",
        "        ds_tr = load_domain(d, tfm_train)\n",
        "        ds_ev = load_domain(d, tfm_eval)\n",
        "        if class_to_idx is None:\n",
        "            class_to_idx = ds_tr.class_to_idx\n",
        "        else:\n",
        "            assert ds_tr.class_to_idx == class_to_idx, \"Class mapping differs across domains.\"\n",
        "        assert ds_ev.class_to_idx == class_to_idx\n",
        "        src_train.append(ds_tr)\n",
        "        per_domain_eval[d] = ds_ev\n",
        "\n",
        "    target_eval = load_domain(target, tfm_eval)\n",
        "    assert target_eval.class_to_idx == class_to_idx\n",
        "    per_domain_eval[target] = target_eval\n",
        "\n",
        "    # Loaders\n",
        "    train_ds = ConcatDataset(src_train)\n",
        "    train_loader = DataLoader(\n",
        "        train_ds, batch_size=batch_size, shuffle=True,\n",
        "        num_workers=num_workers, pin_memory=True,\n",
        "        persistent_workers=(num_workers > 0), drop_last=True\n",
        "    )\n",
        "    eval_loaders = {\n",
        "        d: DataLoader(ds, batch_size=batch_size, shuffle=False,\n",
        "                      num_workers=num_workers, pin_memory=True,\n",
        "                      persistent_workers=(num_workers > 0))\n",
        "        for d, ds in per_domain_eval.items()\n",
        "    }\n",
        "\n",
        "    num_classes = len(target_eval.classes)\n",
        "    return train_loader, eval_loaders, num_classes, target_eval.classes\n",
        "\n",
        "train_loader, eval_loaders, num_classes, classes = make_loaders(\n",
        "    DATA_ROOT, IMG_SIZE, BATCH_SIZE, NUM_WORKERS, SOURCES, TARGET\n",
        ")\n",
        "print(f\"Train size: {len(train_loader.dataset)} | Num classes: {num_classes}\")\n",
        "print(\"Domains loaded:\", list(eval_loaders.keys()))\n",
        "print(\"Classes:\", classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01Z-gRAtZ8oT",
        "outputId": "eb155220-ea8a-4dec-8fc6-bd417c7df54a"
      },
      "id": "01Z-gRAtZ8oT",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 6062 | Num classes: 7\n",
            "Domains loaded: ['art_painting', 'cartoon', 'photo', 'sketch']\n",
            "Classes: ['dog', 'elephant', 'giraffe', 'guitar', 'horse', 'house', 'person']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_resnet50(num_classes: int):\n",
        "    # pretrained ResNet-50, replace final layer\n",
        "    m = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
        "    m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
        "    return m\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loaders, device):\n",
        "    model.eval()\n",
        "    acc = {}\n",
        "    for dname, loader in loaders.items():\n",
        "        correct, total = 0, 0\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "            pred = logits.argmax(1)\n",
        "            correct += (pred == y).sum().item()\n",
        "            total   += y.numel()\n",
        "        acc[dname] = correct / max(total, 1)\n",
        "    return acc\n",
        "\n",
        "\n",
        "def train_erm(\n",
        "    sources,\n",
        "    target,\n",
        "    train_loader,\n",
        "    eval_loaders,\n",
        "    num_classes,\n",
        "    epochs=20,\n",
        "    lr=3e-4,\n",
        "    wd=0.05,\n",
        "    out_dir=\"outputs_erm\",\n",
        "    seed=1337,\n",
        "    use_amp=True,\n",
        "):\n",
        "    np.random.seed(seed); torch.manual_seed(seed)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = build_resnet50(num_classes).to(device)\n",
        "\n",
        "    opt   = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    sched = optim.lr_scheduler.CosineAnnealingLR(opt, T_max=epochs)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=(use_amp and device.type==\"cuda\"))\n",
        "\n",
        "    best_target = 0.0\n",
        "    logs = []\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        seen = 0\n",
        "\n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {ep}/{epochs}\", leave=False)\n",
        "        for x, y in pbar:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "\n",
        "            with torch.cuda.amp.autocast(enabled=(use_amp and device.type==\"cuda\")):\n",
        "                logits = model(x)\n",
        "                loss = loss_fn(logits, y)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(opt)\n",
        "            scaler.update()\n",
        "\n",
        "            running_loss += loss.item() * y.size(0)\n",
        "            seen += y.size(0)\n",
        "\n",
        "        sched.step()\n",
        "\n",
        "        acc = evaluate(model, eval_loaders, device)\n",
        "        src_accs = [acc[d] for d in sources]\n",
        "        avg_src = float(np.mean(src_accs))\n",
        "        worst_src = float(min(src_accs))\n",
        "\n",
        "        # Log\n",
        "        row = {\n",
        "            \"epoch\": ep,\n",
        "            \"train_loss\": running_loss / max(seen, 1),\n",
        "            \"target_acc\": acc[target],\n",
        "            \"avg_source_acc\": avg_src,\n",
        "            \"worst_source_acc\": worst_src,\n",
        "        }\n",
        "        for d in sources + [target]:\n",
        "            row[f\"acc_{d}\"] = acc[d]\n",
        "        logs.append(row)\n",
        "\n",
        "        print(f\"[Ep {ep:02d}] loss={row['train_loss']:.4f} | \"\n",
        "              f\"tgt({target})={acc[target]:.3f} | src_avg={avg_src:.3f} | worst_src={worst_src:.3f}\")\n",
        "\n",
        "        # Save best-by-target\n",
        "        if acc[target] > best_target:\n",
        "            best_target = acc[target]\n",
        "            torch.save(model.state_dict(), os.path.join(out_dir, \"best_model.pt\"))\n",
        "\n",
        "    df = pd.DataFrame(logs)\n",
        "    df.to_csv(os.path.join(out_dir, \"training_log.csv\"), index=False)\n",
        "    print(f\"\\nBest target ({target}) accuracy: {best_target:.3f}\")\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "0SiUxPTkaLYA"
      },
      "id": "0SiUxPTkaLYA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Uses the loaders you already created:\n",
        "# train_loader, eval_loaders, num_classes, classes = make_loaders(...)\n",
        "\n",
        "df_logs = train_erm(\n",
        "    sources=SOURCES,\n",
        "    target=TARGET,\n",
        "    train_loader=train_loader,\n",
        "    eval_loaders=eval_loaders,\n",
        "    num_classes=num_classes,\n",
        "    epochs=20,\n",
        "    lr=3e-4,\n",
        "    wd=0.05,\n",
        "    out_dir=\"outputs_erm\",\n",
        "    seed=1337,\n",
        "    use_amp=True,   # set False if you hit AMP issues\n",
        ")\n",
        "\n",
        "# Peek last few rows\n",
        "df_logs.tail()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "id": "ymgHvjtlab8c",
        "outputId": "71975003-3f10-4596-f5c6-4c3be5bf7055"
      },
      "id": "ymgHvjtlab8c",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 156MB/s]\n",
            "/tmp/ipython-input-2102803089.py:44: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(use_amp and device.type==\"cuda\"))\n",
            "Epoch 1/20:   0%|          | 0/94 [00:00<?, ?it/s]/tmp/ipython-input-2102803089.py:60: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(use_amp and device.type==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 01] loss=0.4052 | tgt(sketch)=0.711 | src_avg=0.967 | worst_src=0.958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 02] loss=0.1278 | tgt(sketch)=0.582 | src_avg=0.976 | worst_src=0.965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 03] loss=0.0820 | tgt(sketch)=0.663 | src_avg=0.985 | worst_src=0.980\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 04] loss=0.0750 | tgt(sketch)=0.601 | src_avg=0.990 | worst_src=0.985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 05] loss=0.0539 | tgt(sketch)=0.549 | src_avg=0.984 | worst_src=0.967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 06] loss=0.0448 | tgt(sketch)=0.701 | src_avg=0.996 | worst_src=0.992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 07] loss=0.0387 | tgt(sketch)=0.734 | src_avg=0.995 | worst_src=0.987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 08] loss=0.0231 | tgt(sketch)=0.644 | src_avg=0.994 | worst_src=0.991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 09] loss=0.0165 | tgt(sketch)=0.697 | src_avg=0.998 | worst_src=0.998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 10] loss=0.0224 | tgt(sketch)=0.694 | src_avg=0.997 | worst_src=0.996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 11] loss=0.0146 | tgt(sketch)=0.724 | src_avg=1.000 | worst_src=0.999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 12] loss=0.0089 | tgt(sketch)=0.707 | src_avg=0.999 | worst_src=0.998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 13] loss=0.0076 | tgt(sketch)=0.729 | src_avg=1.000 | worst_src=1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 14] loss=0.0064 | tgt(sketch)=0.700 | src_avg=1.000 | worst_src=1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 15] loss=0.0026 | tgt(sketch)=0.689 | src_avg=1.000 | worst_src=1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 16] loss=0.0032 | tgt(sketch)=0.729 | src_avg=1.000 | worst_src=1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 17] loss=0.0044 | tgt(sketch)=0.728 | src_avg=1.000 | worst_src=1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 18] loss=0.0039 | tgt(sketch)=0.736 | src_avg=1.000 | worst_src=1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 19] loss=0.0029 | tgt(sketch)=0.728 | src_avg=1.000 | worst_src=1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ep 20] loss=0.0041 | tgt(sketch)=0.729 | src_avg=1.000 | worst_src=1.000\n",
            "\n",
            "Best target (sketch) accuracy: 0.736\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    epoch  train_loss  target_acc  avg_source_acc  worst_source_acc  \\\n",
              "15     16    0.003183    0.729448             1.0               1.0   \n",
              "16     17    0.004430    0.728430             1.0               1.0   \n",
              "17     18    0.003913    0.735811             1.0               1.0   \n",
              "18     19    0.002883    0.728175             1.0               1.0   \n",
              "19     20    0.004060    0.729193             1.0               1.0   \n",
              "\n",
              "    acc_art_painting  acc_cartoon  acc_photo  acc_sketch  \n",
              "15               1.0          1.0        1.0    0.729448  \n",
              "16               1.0          1.0        1.0    0.728430  \n",
              "17               1.0          1.0        1.0    0.735811  \n",
              "18               1.0          1.0        1.0    0.728175  \n",
              "19               1.0          1.0        1.0    0.729193  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1c5cfb8a-099d-4329-b407-92f37737baef\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>target_acc</th>\n",
              "      <th>avg_source_acc</th>\n",
              "      <th>worst_source_acc</th>\n",
              "      <th>acc_art_painting</th>\n",
              "      <th>acc_cartoon</th>\n",
              "      <th>acc_photo</th>\n",
              "      <th>acc_sketch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>0.003183</td>\n",
              "      <td>0.729448</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.729448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17</td>\n",
              "      <td>0.004430</td>\n",
              "      <td>0.728430</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.728430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>0.003913</td>\n",
              "      <td>0.735811</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.735811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>19</td>\n",
              "      <td>0.002883</td>\n",
              "      <td>0.728175</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.728175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>0.004060</td>\n",
              "      <td>0.729193</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.729193</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c5cfb8a-099d-4329-b407-92f37737baef')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1c5cfb8a-099d-4329-b407-92f37737baef button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1c5cfb8a-099d-4329-b407-92f37737baef');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2cfa7964-a46e-4c48-95a8-e13a94d9821d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2cfa7964-a46e-4c48-95a8-e13a94d9821d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2cfa7964-a46e-4c48-95a8-e13a94d9821d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_logs\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 16,\n        \"max\": 20,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          17,\n          20,\n          18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0006406335672700327,\n        \"min\": 0.0028833934759840054,\n        \"max\": 0.00442992101245104,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.00442992101245104,\n          0.0040600376124394705,\n          0.00391272633792238\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0031738263968795945,\n        \"min\": 0.7281751081700178,\n        \"max\": 0.7358106388393993,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.7284296258589972,\n          0.7291931789259354,\n          0.7358106388393993\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_source_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"worst_source_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acc_art_painting\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acc_cartoon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acc_photo\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acc_sketch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0031738263968795945,\n        \"min\": 0.7281751081700178,\n        \"max\": 0.7358106388393993,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.7284296258589972\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "log_path = \"outputs_erm/training_log.csv\"\n",
        "df = pd.read_csv(log_path)\n",
        "\n",
        "best_idx = df[\"target_acc\"].idxmax()\n",
        "best = df.iloc[best_idx]\n",
        "\n",
        "summary = {\n",
        "    \"best_epoch\": int(best[\"epoch\"]),\n",
        "    \"target_sketch_acc\": round(float(best[\"target_acc\"]), 4),\n",
        "    \"avg_source_acc\": round(float(best[\"avg_source_acc\"]), 4),\n",
        "    \"worst_source_acc\": round(float(best[\"worst_source_acc\"]), 4),\n",
        "}\n",
        "for d in SOURCES + [TARGET]:\n",
        "    summary[f\"{d}_acc\"] = round(float(best[f\"acc_{d}\"]), 4)\n",
        "\n",
        "summary\n"
      ],
      "metadata": {
        "id": "nehpNYYiaixX",
        "outputId": "713e5f8d-590b-4263-8e58-2b2ccbf93123",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "nehpNYYiaixX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'best_epoch': 18,\n",
              " 'target_sketch_acc': 0.7358,\n",
              " 'avg_source_acc': 1.0,\n",
              " 'worst_source_acc': 1.0,\n",
              " 'art_painting_acc': 1.0,\n",
              " 'cartoon_acc': 1.0,\n",
              " 'photo_acc': 1.0,\n",
              " 'sketch_acc': 0.7358}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IRMv1"
      ],
      "metadata": {
        "id": "VAg0y8H5yAOQ"
      },
      "id": "VAg0y8H5yAOQ"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "_to_rgb = transforms.Lambda(lambda im: im.convert(\"RGB\"))\n",
        "\n",
        "def make_per_domain_train_loaders(data_root, img_size=224, batch_size=12, num_workers=2, sources=None):\n",
        "    # same train transform as before\n",
        "    tfm_train = transforms.Compose([\n",
        "        _to_rgb,\n",
        "        transforms.RandomResizedCrop(img_size, scale=(0.7, 1.0)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(0.1,0.1,0.1,0.05),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "    ])\n",
        "    loaders = {}\n",
        "    class_to_idx = None\n",
        "    for d in sources:\n",
        "        ds = datasets.ImageFolder(str(Path(data_root)/d), transform=tfm_train)\n",
        "        if class_to_idx is None:\n",
        "          class_to_idx = ds.class_to_idx\n",
        "        else:\n",
        "          assert ds.class_to_idx == class_to_idx\n",
        "        loaders[d] = DataLoader(ds, batch_size=batch_size, shuffle=True,\n",
        "                                num_workers=num_workers, pin_memory=True,\n",
        "                                persistent_workers=(num_workers>0), drop_last=True)\n",
        "    return loaders\n"
      ],
      "metadata": {
        "id": "MX3pbWSax_k3"
      },
      "id": "MX3pbWSax_k3",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, numpy as np, os, random, itertools\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from torch.optim.swa_utils import AveragedModel, SWALR\n",
        "\n",
        "def build_resnet50(num_classes: int):\n",
        "    m = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
        "    # freeze all, then unfreeze layer4+layer3 first; we’ll unfreeze layer2 later\n",
        "    for p in m.parameters(): p.requires_grad = False\n",
        "    for p in m.layer4.parameters(): p.requires_grad = True\n",
        "    for p in m.layer3.parameters(): p.requires_grad = True\n",
        "    m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
        "    return m\n",
        "\n",
        "def set_bn_eval(m):\n",
        "    if isinstance(m, torch.nn.modules.batchnorm._BatchNorm):\n",
        "        m.eval()\n",
        "\n",
        "def irm_penalty(loss, dummy_w):\n",
        "    g = torch.autograd.grad(loss, [dummy_w], create_graph=True)[0]\n",
        "    return torch.sum(g**2)\n",
        "\n",
        "def train_irm(\n",
        "    sources, target, per_domain_train_loaders, eval_loaders, num_classes,\n",
        "    epochs, lr=3e-4, wd=0.0, out_dir=\"outputs_irm\",\n",
        "    seed=1337, use_amp=True,\n",
        "    lambda_warmup_epochs = 3,    # long warmup\n",
        "    lambda_after=10.0,\n",
        "    grad_accum_steps=2,\n",
        "    domains_per_step=2,        # 2 domains per step for stable penalty\n",
        "    unfreeze_layer2_at=10,     # give more capacity mid-training\n",
        "    use_swa=True, swa_start=20 # SWA last few epochs\n",
        "):\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = build_resnet50(num_classes).to(device)\n",
        "    model = model.to(memory_format=torch.channels_last)\n",
        "    model.apply(set_bn_eval)  # freeze BN stats\n",
        "\n",
        "    opt   = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, weight_decay=wd)\n",
        "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=epochs, eta_min=1e-6)\n",
        "    ce    = nn.CrossEntropyLoss()\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=(use_amp and device.type=='cuda'))\n",
        "    torch.set_float32_matmul_precision('medium')\n",
        "\n",
        "    # SWA wrapper (activates after swa_start)\n",
        "    swa_model = AveragedModel(model) if use_swa else None\n",
        "    swa_sched = SWALR(opt, swa_lr=lr*0.5) if use_swa else None  # lr will be overridden after swa_start\n",
        "\n",
        "    # Iterators\n",
        "    domain_iters = {d: iter(per_domain_train_loaders[d]) for d in sources}\n",
        "    domains = list(sources)\n",
        "\n",
        "    best_target = 0.0\n",
        "    logs = []\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    for ep in range(1, epochs+1):\n",
        "        # λ schedule\n",
        "        if ep <= lambda_warmup_epochs:\n",
        "            lam = 1.0\n",
        "        else:\n",
        "            lam = lambda_after\n",
        "        if ep == 6:  # e.g., when changing lam\n",
        "            for g in opt.param_groups:\n",
        "                g['lr'] *= 0.3\n",
        "\n",
        "        # (If you have SWA wired)\n",
        "        if use_swa and ep >= swa_start:\n",
        "            swa_model.update_parameters(model)\n",
        "            swa_sched.step()\n",
        "        else:\n",
        "            sched.step()\n",
        "\n",
        "        # unfreeze layer2 later for extra capacity\n",
        "        if ep == unfreeze_layer2_at:\n",
        "            for p in model.layer2.parameters(): p.requires_grad = True\n",
        "\n",
        "        model.train()\n",
        "        steps = min(len(ld) for ld in per_domain_train_loaders.values())\n",
        "        running_loss = 0.0\n",
        "        running_pen  = 0.0\n",
        "        seen = 0\n",
        "\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        for step in tqdm(range(steps), desc=f\"[IRM+] Epoch {ep}/{epochs}\", leave=False):\n",
        "            # pick K distinct domains this step\n",
        "            chosen = [domains[(step + k) % len(domains)] for k in range(domains_per_step)]\n",
        "            losses, penalties, batch_sizes = [], [], []\n",
        "\n",
        "            for d in chosen:\n",
        "                try:\n",
        "                    x, y = next(domain_iters[d])\n",
        "                except StopIteration:\n",
        "                    domain_iters[d] = iter(per_domain_train_loaders[d])\n",
        "                    x, y = next(domain_iters[d])\n",
        "\n",
        "                x = x.to(device, memory_format=torch.channels_last, non_blocking=True)\n",
        "                y = y.to(device, non_blocking=True)\n",
        "                w = torch.tensor(1.0, requires_grad=True, device=device)\n",
        "\n",
        "                with torch.amp.autocast('cuda', enabled=(use_amp and device.type==\"cuda\")):\n",
        "                    logits = model(x) * w\n",
        "                    loss_d = ce(logits, y)\n",
        "                pen_d = irm_penalty(loss_d, w)\n",
        "\n",
        "                losses.append(loss_d)\n",
        "                penalties.append(pen_d)\n",
        "                batch_sizes.append(y.size(0))\n",
        "\n",
        "            loss = torch.stack(losses).mean()\n",
        "            penalty = torch.stack(penalties).mean()\n",
        "            total = loss + lam * penalty\n",
        "\n",
        "            scaler.scale(total / grad_accum_steps).backward()\n",
        "            running_loss += total.item() * sum(batch_sizes)\n",
        "            running_pen  += penalty.item() * sum(batch_sizes)\n",
        "            seen += sum(batch_sizes)\n",
        "\n",
        "            if (step + 1) % grad_accum_steps == 0:\n",
        "                torch.nn.utils.clip_grad_norm_(filter(lambda p: p.requires_grad, model.parameters()), 1.0)\n",
        "                scaler.step(opt)\n",
        "                scaler.update()\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "\n",
        "        # LR schedule or SWA phase\n",
        "        if use_swa and ep >= swa_start:\n",
        "            swa_model.update_parameters(model)\n",
        "            swa_sched.step()\n",
        "        else:\n",
        "            sched.step()\n",
        "\n",
        "        # eval helper\n",
        "        @torch.no_grad()\n",
        "        def evaluate(m, loaders):\n",
        "            m.eval(); out={}\n",
        "            for name, ld in loaders.items():\n",
        "                c=t=0\n",
        "                for xb,yb in ld:\n",
        "                    xb = xb.to(device, memory_format=torch.channels_last)\n",
        "                    yb = yb.to(device)\n",
        "                    p = m(xb).argmax(1)\n",
        "                    c += (p==yb).sum().item(); t += yb.numel()\n",
        "                out[name]=c/max(t,1)\n",
        "            return out\n",
        "\n",
        "        # If SWA just started or at the end, update BN for SWA model (needs BN stats)\n",
        "        if use_swa and ep == epochs:\n",
        "            # temporarily un-freeze BN for update_bn\n",
        "            def set_bn_train(m):\n",
        "                if isinstance(m, torch.nn.modules.batchnorm._BatchNorm): m.train()\n",
        "            swa_model.apply(set_bn_train)\n",
        "            torch.optim.swa_utils.update_bn(next(iter(eval_loaders.values())), swa_model, device=device)\n",
        "            acc = evaluate(swa_model, eval_loaders)\n",
        "        else:\n",
        "            acc = evaluate(model, eval_loaders)\n",
        "\n",
        "        src_accs = [acc[d] for d in sources]\n",
        "        avg_src, worst_src = float(np.mean(src_accs)), float(min(src_accs))\n",
        "        row = {\n",
        "            \"epoch\": ep,\n",
        "            \"lambda\": lam,\n",
        "            \"train_loss\": running_loss / max(seen,1),\n",
        "            \"irm_penalty\": running_pen / max(seen,1),\n",
        "            \"target_acc\": acc[target],\n",
        "            \"avg_source_acc\": avg_src,\n",
        "            \"worst_source_acc\": worst_src,\n",
        "        }\n",
        "        for d in sources+[target]:\n",
        "            row[f\"acc_{d}\"] = acc[d]\n",
        "        logs.append(row)\n",
        "\n",
        "        print(f\"[IRM+ Ep {ep:02d}] tgt={acc[target]:.3f} | src_avg={avg_src:.3f} | worst_src={worst_src:.3f} | \"\n",
        "              f\"λ={lam:.2f} | pen={row['irm_penalty']:.4f}\")\n",
        "\n",
        "        if acc[target] > best_target:\n",
        "            best_target = acc[target]\n",
        "            torch.save((swa_model if (use_swa and ep>=swa_start) else model).state_dict(),\n",
        "                       os.path.join(out_dir, \"best_model.pt\"))\n",
        "\n",
        "    df = pd.DataFrame(logs)\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    df.to_csv(os.path.join(out_dir, \"training_log.csv\"), index=False)\n",
        "    print(f\"\\n✅ IRM+ best target ({target}) acc: {best_target:.3f}\")\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "vKeTqAZGoRGE"
      },
      "id": "vKeTqAZGoRGE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "per_domain_train = make_per_domain_train_loaders(\n",
        "    data_root=DATA_ROOT,\n",
        "    sources=SOURCES,\n",
        ")\n",
        "\n",
        "df_irm = train_irm(\n",
        "    sources=SOURCES,\n",
        "    target=TARGET,\n",
        "    per_domain_train_loaders=per_domain_train,\n",
        "    eval_loaders=eval_loaders,\n",
        "    num_classes=num_classes,\n",
        "    epochs=20,\n",
        "    lr=3e-4,\n",
        "    wd=0.0,\n",
        "    out_dir=\"outputs_irm\",\n",
        "    lambda_warmup_epochs=3,\n",
        "    lambda_after=10.0,\n",
        "    grad_accum_steps=2,\n",
        "    domains_per_step=2,\n",
        "    unfreeze_layer2_at=6,\n",
        "    use_swa=True, swa_start=12,\n",
        ")\n",
        "best_idx = df_irm[\"target_acc\"].idxmax()\n",
        "best = df_irm.iloc[best_idx]\n",
        "{\n",
        "    \"best_epoch\": int(best[\"epoch\"]),\n",
        "    \"target_sketch_acc\": round(float(best[\"target_acc\"]), 4),\n",
        "    \"avg_source_acc\": round(float(best[\"avg_source_acc\"]), 4),\n",
        "    \"worst_source_acc\": round(float(best[\"worst_source_acc\"]), 4),\n",
        "    \"lambda_used\": float(best[\"lambda\"]),\n",
        "    \"irm_penalty_at_best\": round(float(best[\"irm_penalty\"]), 6),\n",
        "    **{f\"{d}_acc\": round(float(best[f\"acc_{d}\"]), 4) for d in SOURCES+[TARGET]}\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JEAIJnf0yus",
        "outputId": "ff265341-145b-46ac-f178-90de0a827e80"
      },
      "id": "2JEAIJnf0yus",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 220MB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 01] tgt=0.583 | src_avg=0.894 | worst_src=0.793 | λ=1.00 | pen=0.0726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 02] tgt=0.689 | src_avg=0.954 | worst_src=0.927 | λ=1.00 | pen=0.0386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 03] tgt=0.710 | src_avg=0.945 | worst_src=0.900 | λ=1.00 | pen=0.0274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 04] tgt=0.550 | src_avg=0.823 | worst_src=0.761 | λ=10.00 | pen=0.0745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 05] tgt=0.603 | src_avg=0.876 | worst_src=0.819 | λ=10.00 | pen=0.0449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 06] tgt=0.651 | src_avg=0.907 | worst_src=0.873 | λ=10.00 | pen=0.0363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 07] tgt=0.657 | src_avg=0.935 | worst_src=0.909 | λ=10.00 | pen=0.0322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 08] tgt=0.684 | src_avg=0.929 | worst_src=0.898 | λ=10.00 | pen=0.0302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 09] tgt=0.666 | src_avg=0.938 | worst_src=0.910 | λ=10.00 | pen=0.0282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 10] tgt=0.697 | src_avg=0.937 | worst_src=0.911 | λ=10.00 | pen=0.0223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 11] tgt=0.673 | src_avg=0.937 | worst_src=0.907 | λ=10.00 | pen=0.0182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 12] tgt=0.656 | src_avg=0.941 | worst_src=0.913 | λ=10.00 | pen=0.0220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 13] tgt=0.698 | src_avg=0.949 | worst_src=0.926 | λ=10.00 | pen=0.0232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 14] tgt=0.686 | src_avg=0.959 | worst_src=0.939 | λ=10.00 | pen=0.0155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 15] tgt=0.735 | src_avg=0.967 | worst_src=0.953 | λ=10.00 | pen=0.0247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 16] tgt=0.775 | src_avg=0.968 | worst_src=0.955 | λ=10.00 | pen=0.0229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 17] tgt=0.736 | src_avg=0.973 | worst_src=0.959 | λ=10.00 | pen=0.0195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 18] tgt=0.757 | src_avg=0.962 | worst_src=0.942 | λ=10.00 | pen=0.0222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 19] tgt=0.640 | src_avg=0.986 | worst_src=0.981 | λ=10.00 | pen=0.0229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IRM+ Ep 20] tgt=0.682 | src_avg=0.976 | worst_src=0.948 | λ=10.00 | pen=0.0116\n",
            "\n",
            "✅ IRM+ best target (sketch) acc: 0.775\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'best_epoch': 16,\n",
              " 'target_sketch_acc': 0.7753,\n",
              " 'avg_source_acc': 0.968,\n",
              " 'worst_source_acc': 0.9548,\n",
              " 'lambda_used': 10.0,\n",
              " 'irm_penalty_at_best': 0.022888,\n",
              " 'art_painting_acc': 0.9551,\n",
              " 'cartoon_acc': 0.9548,\n",
              " 'photo_acc': 0.994,\n",
              " 'sketch_acc': 0.7753}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Group-DRO"
      ],
      "metadata": {
        "id": "6pPfzwnB3oYA"
      },
      "id": "6pPfzwnB3oYA"
    },
    {
      "cell_type": "code",
      "source": [
        "class RoundRobinIterator:\n",
        "    def __init__(self, loaders_dict):\n",
        "        self.domains = list(loaders_dict.keys())\n",
        "        self.loaders = loaders_dict\n",
        "        self.iters = {d: iter(loaders_dict[d]) for d in self.domains}\n",
        "        self.ptr = 0\n",
        "    def next_batch(self):\n",
        "        d = self.domains[self.ptr]\n",
        "        self.ptr = (self.ptr + 1) % len(self.domains)\n",
        "        try:\n",
        "            x,y = next(self.iters[d])\n",
        "        except StopIteration:\n",
        "            self.iters[d] = iter(self.loaders[d])\n",
        "            x,y = next(self.iters[d])\n",
        "        return d, x, y\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loaders, device):\n",
        "    model.eval()\n",
        "    out = {}\n",
        "    for name, ld in loaders.items():\n",
        "        c = t = 0\n",
        "        for xb, yb in ld:\n",
        "            xb = xb.to(device, memory_format=torch.channels_last)\n",
        "            yb = yb.to(device)\n",
        "            p = model(xb).argmax(1)\n",
        "            c += (p == yb).sum().item()\n",
        "            t += yb.numel()\n",
        "        out[name] = c / max(t, 1)\n",
        "    return out\n",
        "\n",
        "def train_groupdro(\n",
        "    sources, target, per_domain_train_loaders, eval_loaders, num_classes,\n",
        "    epochs=20, lr=3e-4, wd=0.0, eta=0.03,   # eta = EG step for domain weights\n",
        "    out_dir=\"outputs_groupdro\", seed=1337, use_amp=True\n",
        "):\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = build_resnet50(num_classes).to(device)\n",
        "    model = model.to(memory_format=torch.channels_last)\n",
        "    model.apply(set_bn_eval)\n",
        "\n",
        "    opt   = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, weight_decay=wd)\n",
        "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=epochs, eta_min=1e-6)\n",
        "    ce    = nn.CrossEntropyLoss()\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=(use_amp and device.type=='cuda'))\n",
        "    torch.set_float32_matmul_precision('medium')\n",
        "\n",
        "    # Domain weights q (on simplex), initialized uniform\n",
        "    q = torch.ones(len(sources), device=device) / len(sources)\n",
        "    dom2idx = {d:i for i,d in enumerate(sources)}\n",
        "    iterator = RoundRobinIterator(per_domain_train_loaders)\n",
        "\n",
        "    best_tgt = 0.0\n",
        "    logs = []\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    steps_per_epoch = min(len(ld) for ld in per_domain_train_loaders.values())\n",
        "\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train()\n",
        "        for _ in tqdm(range(steps_per_epoch), desc=f\"[GroupDRO] Epoch {ep}/{epochs}\", leave=False):\n",
        "            d, x, y = iterator.next_batch()\n",
        "            x = x.to(device, memory_format=torch.channels_last, non_blocking=True)\n",
        "            y = y.to(device, non_blocking=True)\n",
        "\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            with torch.amp.autocast('cuda', enabled=(use_amp and device.type=='cuda')):\n",
        "                logits = model(x)\n",
        "                loss_d = ce(logits, y)\n",
        "                loss = q[dom2idx[d]] * loss_d     # weighted current-domain loss\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            torch.nn.utils.clip_grad_norm_(filter(lambda p: p.requires_grad, model.parameters()), 1.0)\n",
        "            scaler.step(opt); scaler.update()\n",
        "\n",
        "            # Exponentiated-gradient update on q (adversarial reweighting)\n",
        "            with torch.no_grad():\n",
        "                # increase weight on domains with higher loss\n",
        "                grad_q = torch.zeros_like(q)\n",
        "                grad_q[dom2idx[d]] = loss_d.detach()\n",
        "                q *= torch.exp(eta * grad_q)\n",
        "                q /= q.sum()  # project back to simplex\n",
        "\n",
        "        sched.step()\n",
        "\n",
        "        # Eval\n",
        "        acc = evaluate(model, eval_loaders, device)\n",
        "        src = [acc[d] for d in sources]\n",
        "        row = {\n",
        "            \"epoch\": ep,\n",
        "            \"target_acc\": acc[target],\n",
        "            \"avg_source_acc\": float(np.mean(src)),\n",
        "            \"worst_source_acc\": float(min(src)),\n",
        "            \"q\": q.detach().float().cpu().numpy().tolist(),\n",
        "            **{f\"acc_{d}\": acc[d] for d in sources+[target]}\n",
        "        }\n",
        "        logs.append(row)\n",
        "        print(f\"[GroupDRO Ep {ep:02d}] tgt={acc[target]:.3f} | src_avg={row['avg_source_acc']:.3f} \"\n",
        "              f\"| worst_src={row['worst_source_acc']:.3f} | q={np.round(row['q'],3)}\")\n",
        "\n",
        "        if acc[target] > best_tgt:\n",
        "            best_tgt = acc[target]\n",
        "            torch.save(model.state_dict(), os.path.join(out_dir, \"best_model.pt\"))\n",
        "\n",
        "    df = pd.DataFrame(logs)\n",
        "    df.to_csv(os.path.join(out_dir, \"training_log.csv\"), index=False)\n",
        "    print(f\"\\n✅ GroupDRO best target ({target}) acc: {best_tgt:.3f}\")\n",
        "    return df"
      ],
      "metadata": {
        "id": "OGeeYusk3ogR"
      },
      "id": "OGeeYusk3ogR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "per_domain_train = make_per_domain_train_loaders(\n",
        "    data_root=DATA_ROOT,\n",
        "    sources=SOURCES,\n",
        ")\n",
        "\n",
        "df_gdro = train_groupdro(\n",
        "    sources=SOURCES,\n",
        "    target=TARGET,\n",
        "    per_domain_train_loaders=per_domain_train,\n",
        "    eval_loaders=eval_loaders,\n",
        "    num_classes=num_classes,\n",
        "    epochs=20,        # you can try 20 if it’s stable\n",
        "    lr=3e-4,\n",
        "    wd=0.0,\n",
        "    eta=0.03,         # if unstable, try 0.02; if too slow, 0.1\n",
        "    out_dir=\"outputs_groupdro\",\n",
        "    seed=1337,\n",
        "    use_amp=True\n",
        ")\n",
        "\n",
        "best_idx = df_gdro[\"target_acc\"].idxmax()\n",
        "best = df_gdro.iloc[best_idx]\n",
        "summary_gdro = {\n",
        "    \"best_epoch\": int(best[\"epoch\"]),\n",
        "    \"target_sketch_acc\": round(float(best[\"target_acc\"]), 4),\n",
        "    \"avg_source_acc\": round(float(best[\"avg_source_acc\"]), 4),\n",
        "    \"worst_source_acc\": round(float(best[\"worst_source_acc\"]), 4),\n",
        "    **{f\"{d}_acc\": round(float(best[f'acc_{d}']), 4) for d in SOURCES+[TARGET]},\n",
        "    \"q_at_best\": [round(v, 4) for v in best[\"q\"]],\n",
        "}\n",
        "summary_gdro\n"
      ],
      "metadata": {
        "id": "9sOazNct4_Tf",
        "outputId": "cd21d004-7b9b-429a-d742-9693a5257d3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9sOazNct4_Tf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 185MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GroupDRO Ep 01] tgt=0.432 | src_avg=0.865 | worst_src=0.717 | q=[0.379 0.387 0.234]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GroupDRO Ep 02] tgt=0.609 | src_avg=0.930 | worst_src=0.884 | q=[0.397 0.434 0.169]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GroupDRO Ep 03] tgt=0.616 | src_avg=0.947 | worst_src=0.895 | q=[0.392 0.488 0.12 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GroupDRO Ep 04] tgt=0.675 | src_avg=0.951 | worst_src=0.924 | q=[0.389 0.523 0.088]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GroupDRO Ep 05] tgt=0.685 | src_avg=0.967 | worst_src=0.950 | q=[0.392 0.537 0.071]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GroupDRO Ep 06] tgt=0.765 | src_avg=0.963 | worst_src=0.926 | q=[0.396 0.546 0.058]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GroupDRO Ep 07] tgt=0.739 | src_avg=0.966 | worst_src=0.929 | q=[0.405 0.553 0.041]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GroupDRO Ep 08] tgt=0.755 | src_avg=0.968 | worst_src=0.938 | q=[0.381 0.585 0.033]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GroupDRO Ep 09] tgt=0.755 | src_avg=0.967 | worst_src=0.945 | q=[0.367 0.607 0.026]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GroupDRO Ep 10] tgt=0.730 | src_avg=0.960 | worst_src=0.940 | q=[0.366 0.614 0.02 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GroupDRO Ep 11] tgt=0.703 | src_avg=0.984 | worst_src=0.972 | q=[0.383 0.603 0.015]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GroupDRO Ep 12] tgt=0.776 | src_avg=0.981 | worst_src=0.970 | q=[0.372 0.615 0.013]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GroupDRO Ep 13] tgt=0.786 | src_avg=0.978 | worst_src=0.958 | q=[0.395 0.594 0.011]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GroupDRO Ep 14] tgt=0.782 | src_avg=0.983 | worst_src=0.972 | q=[0.419 0.572 0.008]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GroupDRO Ep 15] tgt=0.784 | src_avg=0.983 | worst_src=0.970 | q=[0.432 0.562 0.006]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GroupDRO Ep 16] tgt=0.795 | src_avg=0.989 | worst_src=0.975 | q=[0.403 0.591 0.005]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GroupDRO Ep 17] tgt=0.802 | src_avg=0.989 | worst_src=0.975 | q=[0.407 0.588 0.005]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GroupDRO Ep 18] tgt=0.793 | src_avg=0.988 | worst_src=0.975 | q=[0.379 0.617 0.004]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GroupDRO Ep 19] tgt=0.786 | src_avg=0.982 | worst_src=0.964 | q=[0.362 0.635 0.004]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GroupDRO Ep 20] tgt=0.798 | src_avg=0.993 | worst_src=0.985 | q=[0.333 0.664 0.003]\n",
            "\n",
            "✅ GroupDRO best target (sketch) acc: 0.802\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'best_epoch': 17,\n",
              " 'target_sketch_acc': 0.8017,\n",
              " 'avg_source_acc': 0.9888,\n",
              " 'worst_source_acc': 0.9748,\n",
              " 'art_painting_acc': 0.9922,\n",
              " 'cartoon_acc': 0.9748,\n",
              " 'photo_acc': 0.9994,\n",
              " 'sketch_acc': 0.8017,\n",
              " 'q_at_best': [0.4071, 0.5882, 0.0046]}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SAM"
      ],
      "metadata": {
        "id": "c6uXa2AdZ6D3"
      },
      "id": "c6uXa2AdZ6D3"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Optimizer\n",
        "\n",
        "class SAM(Optimizer):\n",
        "    \"\"\"Sharpness-Aware Minimization (SAM) wrapper.\n",
        "       Works with SGD/Adam/AdamW. Call first_step(...), then second_step(...).\n",
        "    \"\"\"\n",
        "    def __init__(self, params, base_optimizer, rho=0.05, adaptive=False, **kwargs):\n",
        "        assert rho > 0.0\n",
        "        defaults = dict(rho=rho, adaptive=adaptive, **kwargs)\n",
        "        super().__init__(params, defaults)\n",
        "        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n",
        "        self.param_groups = self.base_optimizer.param_groups  # keep ref\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def _grad_norm(self):\n",
        "        device = self.param_groups[0][\"params\"][0].device\n",
        "        norms = []\n",
        "        for group in self.param_groups:\n",
        "            for p in group[\"params\"]:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad\n",
        "                if group.get(\"adaptive\", False):\n",
        "                    grad = grad * (p.abs() + 1e-12)\n",
        "                norms.append(torch.norm(grad, p=2))\n",
        "        if not norms:\n",
        "            return torch.tensor(0.0, device=device)\n",
        "        return torch.norm(torch.stack(norms), p=2)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def first_step(self, zero_grad=False):\n",
        "        rho = self.param_groups[0][\"rho\"]\n",
        "        adaptive = self.param_groups[0].get(\"adaptive\", False)\n",
        "        grad_norm = self._grad_norm()\n",
        "        scale = rho / (grad_norm + 1e-12)\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            for p in group[\"params\"]:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                self.state[p][\"old_p\"] = p.data.clone()\n",
        "                e_w = p.grad\n",
        "                if adaptive:\n",
        "                    e_w = e_w * (p.abs() + 1e-12)\n",
        "                p.add_(e_w, alpha=scale)\n",
        "\n",
        "        if zero_grad:\n",
        "            self.zero_grad()\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def second_step(self, zero_grad=False):\n",
        "        for group in self.param_groups:\n",
        "            for p in group[\"params\"]:\n",
        "                if \"old_p\" not in self.state[p]:\n",
        "                    continue\n",
        "                p.data.copy_(self.state[p][\"old_p\"])\n",
        "        self.base_optimizer.step()\n",
        "        if zero_grad:\n",
        "            self.zero_grad()\n",
        "\n",
        "    def step(self):\n",
        "        # not used; call first_step/second_step explicitly\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def zero_grad(self, *args, **kwargs):\n",
        "        self.base_optimizer.zero_grad(*args, **kwargs)\n",
        "\n",
        "    def state_dict(self):\n",
        "        return {\n",
        "            \"base\": self.base_optimizer.state_dict(),\n",
        "            \"sam\": super().state_dict(),\n",
        "        }\n",
        "\n",
        "    def load_state_dict(self, state_dict):\n",
        "        self.base_optimizer.load_state_dict(state_dict[\"base\"])\n",
        "        super().load_state_dict(state_dict[\"sam\"])\n"
      ],
      "metadata": {
        "id": "VkuQWzUQZ6Ll"
      },
      "id": "VkuQWzUQZ6Ll",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, numpy as np, os\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from torch.optim.swa_utils import AveragedModel, SWALR, update_bn\n",
        "\n",
        "def build_resnet50_sam(num_classes: int, train_layers=(\"layer3\",\"layer4\",\"fc\")):\n",
        "    m = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
        "    for p in m.parameters(): p.requires_grad = False\n",
        "    if \"layer3\" in train_layers:\n",
        "        for p in m.layer3.parameters(): p.requires_grad = True\n",
        "    if \"layer4\" in train_layers:\n",
        "        for p in m.layer4.parameters(): p.requires_grad = True\n",
        "    m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
        "    return m\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loaders, device):\n",
        "    model.eval()\n",
        "    acc = {}\n",
        "    for name, ld in loaders.items():\n",
        "        c=t=0\n",
        "        for xb, yb in ld:\n",
        "            xb = xb.to(device, memory_format=torch.channels_last)\n",
        "            yb = yb.to(device)\n",
        "            pred = model(xb).argmax(1)\n",
        "            c += (pred==yb).sum().item(); t += yb.numel()\n",
        "        acc[name] = c / max(t,1)\n",
        "    return acc\n",
        "\n",
        "def set_bn_eval(m):\n",
        "    # Freeze BN running stats (affine params still train). Helps SAM stability.\n",
        "    if isinstance(m, torch.nn.modules.batchnorm._BatchNorm):\n",
        "        m.eval()\n",
        "\n",
        "def train_erm_sam(\n",
        "    train_loader, eval_loaders, num_classes,\n",
        "    epochs=20, base_lr=3e-4, wd=1e-4, rho=0.075, use_sgd=False,\n",
        "    out_dir=\"outputs_sam_asam\", seed=1337, use_amp=True,\n",
        "    swa_start_epoch=14\n",
        "):\n",
        "    np.random.seed(seed); torch.manual_seed(seed)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # --- model ---\n",
        "    model = build_resnet50_sam(num_classes).to(device)\n",
        "    model = model.to(memory_format=torch.channels_last)\n",
        "    model.apply(set_bn_eval)  # freeze BN running stats for both passes\n",
        "\n",
        "    # --- optimizer: ASAM (adaptive=True) ---\n",
        "    if use_sgd:\n",
        "        base_opt = optim.SGD\n",
        "        opt = SAM(\n",
        "            model.parameters(), base_optimizer=base_opt,\n",
        "            rho=rho, adaptive=True, lr=base_lr, momentum=0.9,\n",
        "            weight_decay=wd, nesterov=True\n",
        "        )\n",
        "    else:\n",
        "        base_opt = optim.AdamW\n",
        "        opt = SAM(\n",
        "            model.parameters(), base_optimizer=base_opt,\n",
        "            rho=rho, adaptive=True, lr=base_lr, weight_decay=wd\n",
        "        )\n",
        "\n",
        "    # --- LR schedule: warmup + cosine ---\n",
        "    warmup_epochs = 3\n",
        "    warm = torch.optim.lr_scheduler.LinearLR(opt.base_optimizer, start_factor=0.2, total_iters=warmup_epochs)\n",
        "    cos  = torch.optim.lr_scheduler.CosineAnnealingLR(opt.base_optimizer, T_max=epochs - warmup_epochs, eta_min=1e-6)\n",
        "    sched = torch.optim.lr_scheduler.SequentialLR(opt.base_optimizer, [warm, cos], milestones=[warmup_epochs])\n",
        "\n",
        "    # --- SWA (average last few epochs) ---\n",
        "    use_swa = True\n",
        "    swa_model = AveragedModel(model) if use_swa else None\n",
        "    swa_sched = SWALR(opt.base_optimizer, swa_lr=base_lr*0.5) if use_swa else None\n",
        "\n",
        "    # --- loss, AMP, misc ---\n",
        "    ce = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=(use_amp and device.type=='cuda'))\n",
        "    torch.set_float32_matmul_precision('medium')\n",
        "\n",
        "    best_tgt = 0.0\n",
        "    logs = []\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train()\n",
        "        running_loss = 0.0; seen = 0\n",
        "\n",
        "        # (optional) unfreeze a bit more capacity after warmup\n",
        "        if ep == warmup_epochs + 1:\n",
        "            if hasattr(model, \"layer2\"):\n",
        "                for p in model.layer2.parameters(): p.requires_grad = True\n",
        "\n",
        "        for xb, yb in tqdm(train_loader, desc=f\"[SAM/ASAM] Epoch {ep}/{epochs}\", leave=False):\n",
        "            xb = xb.to(device, memory_format=torch.channels_last, non_blocking=True)\n",
        "            yb = yb.to(device, non_blocking=True)\n",
        "\n",
        "            # ---- pass 1: ascent (compute epsilon) ----\n",
        "            opt.zero_grad()\n",
        "            with torch.amp.autocast('cuda', enabled=(use_amp and device.type=='cuda')):\n",
        "                logits = model(xb)\n",
        "                loss = ce(logits, yb)\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            # DO NOT unscale here\n",
        "            opt.first_step(zero_grad=True)\n",
        "\n",
        "            # ---- pass 2: descent at w+ε ----\n",
        "            with torch.amp.autocast('cuda', enabled=(use_amp and device.type=='cuda')):\n",
        "                logits_adv = model(xb)\n",
        "                loss_adv = ce(logits_adv, yb)\n",
        "\n",
        "            scaler.scale(loss_adv).backward()\n",
        "            scaler.unscale_(opt.base_optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            scaler.step(opt.base_optimizer)\n",
        "            scaler.update()\n",
        "            opt.second_step(zero_grad=True)\n",
        "\n",
        "            running_loss += loss_adv.item() * yb.size(0)\n",
        "            seen += yb.size(0)\n",
        "\n",
        "        # LR scheduling / SWA update\n",
        "        if use_swa and ep >= swa_start_epoch:\n",
        "            swa_model.update_parameters(model)\n",
        "            swa_sched.step()\n",
        "        else:\n",
        "            sched.step()\n",
        "\n",
        "        # Eval current model (not SWA)\n",
        "        acc_now = evaluate(model, eval_loaders, device)\n",
        "        src_domains = [d for d in eval_loaders.keys() if d != \"sketch\"]\n",
        "        src_accs = [acc_now[d] for d in src_domains]\n",
        "        row = {\n",
        "            \"epoch\": ep,\n",
        "            \"train_loss\": running_loss / max(seen,1),\n",
        "            \"target_acc\": acc_now.get(\"sketch\", 0.0),\n",
        "            \"avg_source_acc\": float(np.mean(src_accs)) if src_accs else 0.0,\n",
        "            \"worst_source_acc\": float(min(src_accs)) if src_accs else 0.0,\n",
        "            **{f\"acc_{k}\": v for k,v in acc_now.items()}\n",
        "        }\n",
        "        logs.append(row)\n",
        "        print(f\"[SAM/ASAM Ep {ep:02d}] tgt={row['target_acc']:.3f} | src_avg={row['avg_source_acc']:.3f} | worst_src={row['worst_source_acc']:.3f}\")\n",
        "\n",
        "        if row[\"target_acc\"] > best_tgt:\n",
        "            best_tgt = row[\"target_acc\"]\n",
        "            torch.save(model.state_dict(), os.path.join(out_dir, \"best_model.pt\"))\n",
        "\n",
        "    # ---- Final SWA evaluation ----\n",
        "    if use_swa:\n",
        "        # temporarily unfreeze BN running stats to compute them for SWA weights\n",
        "        def set_bn_train(m):\n",
        "            if isinstance(m, torch.nn.modules.batchnorm._BatchNorm): m.train()\n",
        "        swa_model.apply(set_bn_train)\n",
        "        update_bn(train_loader, swa_model, device=device)\n",
        "        acc_swa = evaluate(swa_model, eval_loaders, device)\n",
        "        tgt_swa = acc_swa.get(\"sketch\", 0.0)\n",
        "        print(f\"✅ SWA final target (sketch) accuracy: {tgt_swa:.3f}\")\n",
        "        torch.save(swa_model.state_dict(), os.path.join(out_dir, \"best_model_swa.pt\"))\n",
        "\n",
        "    df = pd.DataFrame(logs)\n",
        "    df.to_csv(os.path.join(out_dir, \"training_log.csv\"), index=False)\n",
        "    print(f\"✅ SAM/ASAM best target (sketch) accuracy during training: {best_tgt:.3f}\")\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "mQLSftSLaYEZ"
      },
      "id": "mQLSftSLaYEZ",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "per_domain_train = make_per_domain_train_loaders(\n",
        "    data_root=DATA_ROOT,\n",
        "    sources=SOURCES,\n",
        ")\n",
        "\n",
        "df_sam = train_erm_sam(\n",
        "    train_loader=train_loader,\n",
        "    eval_loaders=eval_loaders,\n",
        "    num_classes=num_classes,\n",
        "    epochs=20,\n",
        "    base_lr=3e-4,     # AdamW LR\n",
        "    wd=1e-4,\n",
        "    rho=0.075,        # ASAM radius; 0.05–0.1 are common\n",
        "    use_sgd=False,    # AdamW + ASAM (recommended)\n",
        "    out_dir=\"outputs_sam_asam\",\n",
        "    seed=1337,\n",
        "    use_amp=True,\n",
        "    swa_start_epoch=14\n",
        ")\n",
        "best_idx = df_sam[\"target_acc\"].idxmax()\n",
        "best = df_sam.iloc[best_idx]\n",
        "{\n",
        "    \"best_epoch\": int(best[\"epoch\"]),\n",
        "    \"target_sketch_acc\": round(float(best[\"target_acc\"]), 4),\n",
        "    \"avg_source_acc\": round(float(best[\"avg_source_acc\"]), 4),\n",
        "    \"worst_source_acc\": round(float(best[\"worst_source_acc\"]), 4),\n",
        "    **{f\"{k}\": round(float(best[f'acc_{k}']),4) for k in eval_loaders.keys()}\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAisNiIhafbe",
        "outputId": "398e7376-94c7-4f6b-a5ce-0b3786db0f04"
      },
      "id": "mAisNiIhafbe",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 208MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAM/ASAM Ep 01] tgt=0.551 | src_avg=0.961 | worst_src=0.937\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAM/ASAM Ep 02] tgt=0.667 | src_avg=0.994 | worst_src=0.992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAM/ASAM Ep 03] tgt=0.607 | src_avg=0.992 | worst_src=0.988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAM/ASAM Ep 04] tgt=0.610 | src_avg=0.992 | worst_src=0.988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAM/ASAM Ep 05] tgt=0.690 | src_avg=0.998 | worst_src=0.997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAM/ASAM Ep 06] tgt=0.677 | src_avg=0.996 | worst_src=0.996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAM/ASAM Ep 07] tgt=0.719 | src_avg=0.998 | worst_src=0.997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAM/ASAM Ep 08] tgt=0.722 | src_avg=0.999 | worst_src=0.999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAM/ASAM Ep 09] tgt=0.718 | src_avg=1.000 | worst_src=1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAM/ASAM Ep 10] tgt=0.677 | src_avg=0.999 | worst_src=0.999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAM/ASAM Ep 11] tgt=0.738 | src_avg=1.000 | worst_src=1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAM/ASAM Ep 12] tgt=0.723 | src_avg=1.000 | worst_src=1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAM/ASAM Ep 13] tgt=0.673 | src_avg=1.000 | worst_src=1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAM/ASAM Ep 14] tgt=0.766 | src_avg=1.000 | worst_src=1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAM/ASAM Ep 15] tgt=0.731 | src_avg=1.000 | worst_src=1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAM/ASAM Ep 16] tgt=0.747 | src_avg=1.000 | worst_src=1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAM/ASAM Ep 17] tgt=0.733 | src_avg=1.000 | worst_src=1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAM/ASAM Ep 18] tgt=0.658 | src_avg=1.000 | worst_src=1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAM/ASAM Ep 19] tgt=0.712 | src_avg=1.000 | worst_src=1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAM/ASAM Ep 20] tgt=0.705 | src_avg=1.000 | worst_src=1.000\n",
            "✅ SWA final target (sketch) accuracy: 0.745\n",
            "✅ SAM/ASAM best target (sketch) accuracy during training: 0.766\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'best_epoch': 14,\n",
              " 'target_sketch_acc': 0.7658,\n",
              " 'avg_source_acc': 1.0,\n",
              " 'worst_source_acc': 1.0,\n",
              " 'art_painting': 1.0,\n",
              " 'cartoon': 1.0,\n",
              " 'photo': 1.0,\n",
              " 'sketch': 0.7658}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xQWlbS-_RxdO"
      },
      "id": "xQWlbS-_RxdO"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jR7EOggbRwre"
      },
      "id": "jR7EOggbRwre",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f0df87b7809748ecbead61c4150fb53e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_289c23d0a38049bd9d64ffda5a321d1a",
              "IPY_MODEL_b62af46eb8a44dd29409ae640adcf324",
              "IPY_MODEL_34ff2f4f644647f19cebd935ebb52638"
            ],
            "layout": "IPY_MODEL_a1334ab8f77540aea2bbc476eeeb579b"
          }
        },
        "289c23d0a38049bd9d64ffda5a321d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93f5005bb41243be9db1c4f1ea66f3ae",
            "placeholder": "​",
            "style": "IPY_MODEL_a0e359e2805143bfae96797663a2e28e",
            "value": "README.md: "
          }
        },
        "b62af46eb8a44dd29409ae640adcf324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa40f0e52cae4c72a911077760240453",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_21f19324ab394f5c897ab262d2bb67a9",
            "value": 1
          }
        },
        "34ff2f4f644647f19cebd935ebb52638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1e83dc07d3d459f92fb6e1a6e7cce96",
            "placeholder": "​",
            "style": "IPY_MODEL_c62e2574e5f14e11b35c6c1972f3fd85",
            "value": " 3.89k/? [00:00&lt;00:00, 100kB/s]"
          }
        },
        "a1334ab8f77540aea2bbc476eeeb579b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93f5005bb41243be9db1c4f1ea66f3ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0e359e2805143bfae96797663a2e28e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa40f0e52cae4c72a911077760240453": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "21f19324ab394f5c897ab262d2bb67a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1e83dc07d3d459f92fb6e1a6e7cce96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c62e2574e5f14e11b35c6c1972f3fd85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "497b98d3961746b8963992a55d113daf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10177b20de8244d884b705385c089709",
              "IPY_MODEL_a60b70d19b274b879f7bb8d14d4c8e19",
              "IPY_MODEL_2ce3e5874f5e483389138402545b11e8"
            ],
            "layout": "IPY_MODEL_3456c8b92bb14cf3baccf7e111251e54"
          }
        },
        "10177b20de8244d884b705385c089709": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_109cc73be387421da114780c6d9f3eb1",
            "placeholder": "​",
            "style": "IPY_MODEL_8744ac9d325941d3b2475e9c0625f7f3",
            "value": "data/train-00000-of-00001.parquet: 100%"
          }
        },
        "a60b70d19b274b879f7bb8d14d4c8e19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3937f11ad36d444b8e55509df2fe9123",
            "max": 191395900,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1417139cfda45aa8366c2856cfe517b",
            "value": 191395900
          }
        },
        "2ce3e5874f5e483389138402545b11e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_372b69046a0d4d2793b20554cf01a6c8",
            "placeholder": "​",
            "style": "IPY_MODEL_d05e42264e024c25b17e247767b7b10c",
            "value": " 191M/191M [00:04&lt;00:00, 42.1MB/s]"
          }
        },
        "3456c8b92bb14cf3baccf7e111251e54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "109cc73be387421da114780c6d9f3eb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8744ac9d325941d3b2475e9c0625f7f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3937f11ad36d444b8e55509df2fe9123": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1417139cfda45aa8366c2856cfe517b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "372b69046a0d4d2793b20554cf01a6c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d05e42264e024c25b17e247767b7b10c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "324fc7031c304b27b709fa816dfde805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87d781312aee4220b270ceee1b6e3c8d",
              "IPY_MODEL_668c8ac529bb4f64ae76b93eedce374a",
              "IPY_MODEL_4fcc9641a563401f9fcd1b36967f5eba"
            ],
            "layout": "IPY_MODEL_81595689dab3475186f2ce1f86e1988e"
          }
        },
        "87d781312aee4220b270ceee1b6e3c8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35d2b0ff19c5462983116731fb328551",
            "placeholder": "​",
            "style": "IPY_MODEL_a74b05c612624bfaa2e0ad17bc11b6cc",
            "value": "Generating train split: 100%"
          }
        },
        "668c8ac529bb4f64ae76b93eedce374a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f68577c2276c4028b721fcd3a0332111",
            "max": 9991,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_abc903af9ea04abab6f5bdac0024f80f",
            "value": 9991
          }
        },
        "4fcc9641a563401f9fcd1b36967f5eba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87ade3989ab94f6eab370eeb1ce60a11",
            "placeholder": "​",
            "style": "IPY_MODEL_2b645addcfba47bca4e5f50a05c3d9b3",
            "value": " 9991/9991 [00:00&lt;00:00, 15773.54 examples/s]"
          }
        },
        "81595689dab3475186f2ce1f86e1988e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35d2b0ff19c5462983116731fb328551": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a74b05c612624bfaa2e0ad17bc11b6cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f68577c2276c4028b721fcd3a0332111": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abc903af9ea04abab6f5bdac0024f80f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "87ade3989ab94f6eab370eeb1ce60a11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b645addcfba47bca4e5f50a05c3d9b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}